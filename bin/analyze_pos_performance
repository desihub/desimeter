#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Tool for analyzing positioner performance. Typically operates on data tables
retrieved using the "get_posmoves --with-calib" tool.
"""

# command line argument parsing
import argparse
parser = argparse.ArgumentParser(description=__doc__)
parser.add_argument('-i', '--infiles', type=str, required=True, nargs='*',
                    help='Path to input csv file(s), containing results from "get_posmoves --with-calib" ' +
                         '(see that function''s help for full syntax). Regex is ok (like M*.csv). Multiple ' +
                         'file args are also ok (like M00001.csv M00002.csv M01*.csv).')
parser.add_argument('-o', '--outdir', type=str, required=True, help='Path to directory where to save output files.')
parser.add_argument('-np', '--n_processes_max', type=int, default=None,  help='max number of processors to use')
args = parser.parse_args()

# proceed with bulk of imports
import os
import glob
import multiprocessing
import numpy as np
from astropy.table import Table

# paths
infiles = []
for s in args.infiles:
    these = glob.glob(s)
    infiles.extend(these)
infiles = [os.path.realpath(p) for p in infiles]
save_dir = os.path.realpath(args.outdir)
if not os.path.isdir(save_dir):
    os.path.os.makedirs(save_dir)

# data identifiers and keywords
required = {'POS_ID', 'POS_MOVE_INDEX', 'POS_T', 'POS_P', 'PTL_X', 'PTL_Y',
            'LENGTH_R1', 'LENGTH_R2', 'OFFSET_X', 'OFFSET_Y', 'OFFSET_T', 'OFFSET_P',
            'MOVE_CMD', 'EXPOSURE_ID', 'EXPOSURE_ITER'}
optional = {'DATE', 'LOG_NOTE'}
sequence_note_prefix = 'sequence: '

# function defs
def nulls(*args):
    '''Returns set of indexes for null entries in one or more argued arrays.'''
    special_null_cases = {'None', 'none', '(null)', 'null'}
    idxs = set()
    for array in args:
        idxs |= {i for i in range(len(array)) if not(array[i]) or array[i] in special_null_cases}
    return idxs

def read(path):
    '''Read in data from disk. If data multiple posids, their respective data
    will be returned in multiple tables.
    
    Basic validation that the required data exists will be performed. This includes
    checking that the data includes actual moves. Thus the function is tolerant of
    data files for non-moving positioners --- they will be automatically skipped.
    
    INPUTS:  path ... must be a csv file, including move and calibration data
    OUTPUT:  data ... dict with keys = posids and values = astropy tables
    '''
    data = {}
    if 'csv' not in path:
        return data  # i.e. skip non-data files
    table = Table.read(path)
    missing = required - set(table.columns)
    if any(missing):
        print(f'Skipped data at {path} due to missing columns {missing}')
        return data
    posids = set(table['POS_ID'])
    for posid in posids:
        selection = table['POS_ID'] == posid
        this = table[selection]
        no_move = nulls(table['MOVE_CMD'])
        if len(no_move) == len(table):
            print(f'Skipped data at {path} (contains no moves)')
        else:
            data[posid] = this
            print(f'Read data at {path}')
    return data

def remove_nonmoving_rows(table):
    '''Deletes rows with no move.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  new ... copy of table, with equal or fewer rows
    '''
    new = table.copy()
    null_check_cols = ['MOVE_CMD', 'PTL_X', 'PTL_Y', 'EXPOSURE_ID']
    null_check_arrays = [new[key].tolist() for key in null_check_cols]
    null_idxs = nulls(*null_check_arrays)
    exp_iters = new['EXPOSURE_ITER'].tolist()  # special handling because value of 0 is ok
    null_iters = {i for i in nulls(exp_iters) if exp_iters[i] != 0}
    null_idxs |= null_iters
    new.remove_rows(list(null_idxs))
    return new

def remove_unused_columns(table):
    '''Deletes unnecessary columns, for easier data viewing.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  new ... copy of table, with equal or fewer columns
    '''
    new = table.copy()
    useless = set(new.columns) - required - optional
    new.remove_columns(list(useless))
    return new

def analyze(table):
    '''Analyze the data for one table, containing one positioner's data.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  (data, msg) ... data is a single-element dict with key = posid and value = astropy tables
                         ... msg is a string suitable for printing at stdout
    '''
    data, msg = {}, ''
    table = remove_nonmoving_rows(table)
    table = remove_unused_columns(table)
    table.sort('POS_MOVE_INDEX')
    posids = set(table['POS_ID'])
    assert len(posids) == 1, f'error: input to analyze should be a table with only one posid, not {posids}'
    posid = posids.pop()
    data[posid] = table
    return data, msg    

# read in the data files
data = {}
for path in infiles:
    this_data = read(path)
    data.update(this_data)

# containers / handlers for multiprocessed analysis data
results = {}
def store_result(result, msg):
    if data:
        results.update(result)
    if msg:
        print(msg)

single_process = args.n_processes_max == 1  # useful for debugging
if __name__ == '__main__':
    if single_process:
        for table in data.values():
            data, msg = analyze(table)
            store_result(data, msg)
    else:
        with multiprocessing.Pool(processes=args.n_processes_max) as pool:
            pool_results = pool.imap(analyze, data.values())
            pool.close()
            pool.join()
        for result in pool_results:
            store_result(*result)