#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Tool for analyzing positioner performance. Typically operates on data tables
retrieved using the "get_posmoves --with-calib" tool.
"""

# command line argument parsing
import argparse
parser = argparse.ArgumentParser(description=__doc__)
parser.add_argument('-i', '--infiles', type=str, required=True, nargs='*',
                    help='Path to input csv file(s), containing results from "get_posmoves --with-calib" ' +
                         '(see that function''s help for full syntax). Regex is ok (like M*.csv). Multiple ' +
                         'file args are also ok (like M00001.csv M00002.csv M01*.csv), as is a directory ' +
                         'that contains the files.')
parser.add_argument('-o', '--outdir', type=str, required=True, help='Path to directory where to save output files.')
parser.add_argument('-np', '--n_processes_max', type=int, default=None,  help='max number of processors to use')
args = parser.parse_args()

# proceed with bulk of imports
import os
import glob
import multiprocessing
import numpy as np
from astropy.table import Table, vstack
from astropy.time import Time
import desimeter.transform.pos2ptl as pos2ptl
import matplotlib.pyplot as plt

# paths
infiles = []
for s in args.infiles:
    these = glob.glob(s)
    for this in these:
        if os.path.isdir(this):
            contents = os.listdir(this)
            contents = [os.path.join(this, file) for file in contents]
            infiles.extend(contents)
        else:
            infiles.append(this)
infiles = [os.path.realpath(p) for p in infiles]
save_dir = os.path.realpath(args.outdir)
if not os.path.isdir(save_dir):
    os.path.os.makedirs(save_dir)

# data identifiers and keywords
required = {'PETAL_ID', 'POS_ID', 'POS_MOVE_INDEX', 'POS_T', 'POS_P', 'PTL_X', 'PTL_Y',
            'LENGTH_R1', 'LENGTH_R2', 'OFFSET_X', 'OFFSET_Y', 'OFFSET_T', 'OFFSET_P',
            'MOVE_CMD', 'EXPOSURE_ID', 'EXPOSURE_ITER', 'DEVICE_LOC', 'DATE', 'LOG_NOTE'}
sequence_note_prefix = 'sequence: '

# statistics functions for summarizing errors
stat_funcs = {'max': max, 'min': min, 'mean': np.mean, 'median': np.median,
              'std': np.std, 'rms': lambda X: (sum(x**2 for x in X)/len(X))**0.5}

# function defs
def nulls(*args):
    '''Returns set of indexes for null entries in one or more argued arrays.'''
    special_null_cases = {'None', 'none', '(null)', 'null'}
    idxs = set()
    for array in args:
        idxs |= {i for i in range(len(array)) if not(array[i]) or array[i] in special_null_cases}
    return idxs

def tokenize_note(log_note):
    '''Returns list of tokens in a LOG_NOTE entry.'''
    tokens = log_note.split(';')
    tokens = [token.strip() for token in tokens]
    return tokens

def parse_val(string, separator=' ', typefunc=int):
    '''Parse a number out of typical token format from LOG_NOTE strings.'''
    split = string.split(separator)
    val = typefunc(split[1]) if len(split) > 0 else None
    return val

def remove_nonmoving_rows(table):
    '''Deletes rows with no move.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  new ... copy of table, with equal or fewer rows
    '''
    new = table.copy()
    null_check_cols = ['MOVE_CMD', 'PTL_X', 'PTL_Y', 'EXPOSURE_ID']
    null_check_arrays = [new[key].tolist() for key in null_check_cols]
    null_idxs = nulls(*null_check_arrays)
    exp_iters = new['EXPOSURE_ITER'].tolist()  # special handling because value of 0 is ok
    null_iters = {i for i in nulls(exp_iters) if exp_iters[i] != 0}
    null_idxs |= null_iters
    new.remove_rows(list(null_idxs))
    return new

def remove_unused_columns(table):
    '''Deletes unnecessary columns, for easier data viewing.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  new ... copy of table, with equal or fewer columns
    '''
    new = table.copy()
    useless = set(new.columns) - required
    new.remove_columns(list(useless))
    return new

def read(path):
    '''Read in data from disk. If data has multiple posids, their respective data
    will be returned in multiple tables.
    
    Basic validation that the required data exists will be performed. This includes
    checking that the data includes actual moves. Thus the function is tolerant of
    data files for non-moving positioners --- they will be automatically skipped.
    
    INPUTS:  path ... must be a csv file, including move and calibration data
    OUTPUT:  data ... dict with keys = posids and values = astropy tables
    '''
    data = {}
    if 'csv' not in path:
        return data  # i.e. skip non-data files
    table = Table.read(path)
    missing = required - set(table.columns)
    if any(missing):
        print(f'Skipped data at {path} due to missing columns {missing}')
        return data
    initial_posids = set(table['POS_ID'])
    table = remove_unused_columns(table)
    table = remove_nonmoving_rows(table)
    posids = set(table['POS_ID'])
    posids_removed = initial_posids - posids
    if any(posids_removed):
        print(f'Skipped data for {posids_removed} which contained no moves in {path}')
    for posid in posids:
        selection = table['POS_ID'] == posid
        this = table[selection]
        data[posid] = this
        print(f'Read data for {posid} at {path}')
    return data

def calc_errors(table):
    '''Identifies measured and target values, then calculates errors.
    
    INPUTS:  table ... astropy table containing 'PTL_X', 'PTL_Y', 'POS_T', 'POS_P',
                       'LENGTH_R1', 'LENGTH_R2', 'OFFSET_T', 'OFFSET_P', 'OFFSET_X',
                       'OFFSET_Y'
    OUTPUT:  copy of table, where measured data columns will have _MEAS  appended to
             their names (for clarity) and new columns will be added with _TARG suffix,
             as well as new columns with ERR_ prefix
    '''
    new = table.copy()
    for key in ['PTL_X', 'PTL_Y', 'PTL_Z', 'OBS_X', 'OBS_Y']:
        if key in new.columns:
            new.rename_column(key, f'{key}_MEAS')
    meas_x, meas_y = new['PTL_X_MEAS'], new['PTL_Y_MEAS']
    targ_x, targ_y = pos2ptl.int2ptl(t_int=new['POS_T'], p_int=new['POS_P'],
                                     r1=new['LENGTH_R1'], r2=new['LENGTH_R1'],
                                     t_offset=new['OFFSET_T'], p_offset=new['OFFSET_P'],
                                     x_offset=new['OFFSET_X'], y_offset=new['OFFSET_Y'])
    new['PTL_X_TARG'] = targ_x
    new['PTL_Y_TARG'] = targ_y
    new['ERR_X'] = meas_x - targ_x
    new['ERR_Y'] = meas_y - targ_y
    new['ERR_XY'] = np.hypot(new['ERR_X'], new['ERR_Y'])
    return new

def identify_submoves(table):
    '''Searches LOG_NOTE field to identify submoves (i.e. correction moves).
    
    INPUTS:  table ... astropy table containing 'LOG_NOTE' and 'EXPOSURE_ID'
    OUTPUT:  copy of table, with new columns 'MOVE' and 'SUBMOVE', containing
             integer IDs identifying any moves and submoves.
             
    Note that 'MOVE' values may not be unique, if the dataset includes multiple
    tests. In such cases, uniqueness can be determined by inspecting also the
    EXPOSURE_ID field --- within which MOVE *will* be unique. Additionally, note
    that 'MOVE' integers may not correspond 1:1 with those given in the LOG_NOTE
    fields, again due to handling of uniqueness corner cases. However, 'SUBMOVE'
    ids *will* correspond exactly to those in LOG_NOTE.
    '''
    new = table.copy()
    new.sort('POS_MOVE_INDEX')
    move_counter = -1
    moves = []
    submoves = []
    last_expid = new['EXPOSURE_ID'][0]
    last_named_move = None  # different from move_counter ... this is from LOG_NOTE field
    for i in range(len(new)):
        expid = new['EXPOSURE_ID'][i]
        if expid != last_expid:
            move_counter = -1
            last_expid = expid
        note = new['LOG_NOTE'][i]
        if 'submove' not in note:
            move_counter += 1
            submove = 0
        else:
            tokens = tokenize_note(note)
            found_move, found_submove = False, False
            for token in tokens:
                if token.find('move') == 0:
                    named_move = parse_val(token)
                    found_move = True
                if token.find('submove') == 0:
                    submove = parse_val(token)
                    found_submove = True
            assert found_move and found_submove, f'move/submove parsing error of LOG_NOTE: {note}'
            if named_move != last_named_move:
                move_counter += 1
                last_named_move = named_move
        moves.append(move_counter)
        submoves.append(submove)
    new['MOVE'] = moves
    new['SUBMOVE'] = submoves
    return new

def analyze(table):
    '''Analyze the data for one table, containing one positioner's data.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  (new, stats, msg)
    
    "new" is an astropy table, containing data copied from "table", as well as some
    new columns like calculated error values.
    
    "stats" is another  astropy table, containing summary error statistics for
    each submove in "table".
    
    "msg" is a string suitable for printing at stdout, may be ''
    '''
    msg = ''
    new = table.copy()
    new.sort('POS_MOVE_INDEX')
    posids = set(new['POS_ID'])
    assert len(posids) == 1, f'error: input to analyze should be a table with only one posid, not {posids}'
    posid = posids.pop()
    new = calc_errors(new)
    new = identify_submoves(new)
    stats_dict = {name:[] for name in ['POS_ID', 'SUBMOVE'] + list(stat_funcs)}
    submoves = sorted(set(new['SUBMOVE']))
    for submove in submoves:
        stats_dict['POS_ID'].append(posid)
        stats_dict['SUBMOVE'].append(submove)
        selection = new['SUBMOVE'] == submove
        err_xy = new['ERR_XY'][selection].tolist()
        for name, func in stat_funcs.items():
            stats_dict[name].append(func(err_xy))
    stats = Table(stats_dict)
    return new, stats, msg    

def init_plot(figsize=(8,6), dpi=150):
    '''Initialize a plot. Returns figure handle.'''
    plt.ioff()
    fig = plt.figure(figsize=figsize, dpi=dpi)
    plt.clf()
    return fig

def save_and_close_plot(fig, savepath):
    '''Save plot to disk and close. Argue the figure handle to be closed, and the
    path where to save the image. Extension determines image format.'''
    plt.savefig(savepath, bbox_inches='tight')
    plt.close(fig)
    
def get_span(table, prefix='PTL_X'):
    '''Returns max - min for all measured and target 'PTL_X' or 'PTL_Y' data in table.'''
    vec = table[f'{prefix}_TARG'].tolist() + table[f'{prefix}_MEAS'].tolist()
    return max(vec) - min(vec)

def plot_petal(table, petal_id, submove=0):
    '''Plot all targets and measurements for positioners on a given petal.
    
    INPUT:  table ... astropy table, as generated by analyze()
            petal_id ... int, petal id number
            submove ... int, specify which submove to plot
    OUTPUT: (path, msg) ... path to saved image file, will be '' if nothing saved
                            msg is a string suitable for printing at stdout, which may be ''
    '''
    msg = ''
    sel1 = table['PETAL_ID'] == petal_id
    sel2 = table['SUBMOVE'] == submove
    selection = [sel1[i] and sel2[i] for i in range(len(table))]
    assert any(selection)
    t = table[selection]
    data_width_mm = get_span(t, 'PTL_X')
    data_height_mm = get_span(t, 'PTL_Y')
    plot_width_in = 10
    plot_height_in = 8
    dots_per_mm = 10
    dpi = max(data_width_mm * dots_per_mm / plot_width_in,
              data_height_mm * dots_per_mm / plot_height_in)
    dpi = int(np.ceil(dpi))
    dpi = max(dpi, 150)
    fig = init_plot(figsize=(plot_width_in, plot_height_in), dpi=dpi)

    for suffix, desc in {'TARG':'target', 'MEAS':'measured'}.items():
        shape = 'o' if suffix == 'TARG' else '+'
        plt.plot(t[f'PTL_X_{suffix}'], t[f'PTL_Y_{suffix}'], shape, label=desc)
    posids = set(table['POS_ID'])
    for posid in posids:
        selection = t['POS_ID'] == posid
        label_x = np.mean(t['PTL_X_TARG'][selection])
        label_y = np.mean(t['PTL_Y_TARG'][selection])
        loc = t['DEVICE_LOC'][selection][0]
        label = f'{posid}\n({loc})'
        plt.annotate(s=label, xy=(label_x, label_y), xycoords='data', 
                     horizontalalignment='center', verticalalignment='top',
                     fontfamily='monospace', fontsize='small')
    plt.xlabel('PTL_X (mm)')
    plt.ylabel('PTL_Y (mm)')
    expids = sorted(set(t['EXPOSURE_ID']))
    expids_str = '-'.join([str(x) for x in expids])
    dates = {datetime.split(' ')[0] for datetime in t['DATE']}
    dates = sorted(dates)
    plt.title(f'Petal {petal_id},  submove: {submove}' +
              f'\nExposure ID(s): {expids},  Date(s) measured: {dates}' +
              f'\nDate analyzed: {Time.now().iso}')
    plt.legend(loc='upper left')
    plt.axis('equal')
    path = os.path.join(save_dir, f'petal-{petal_id}_expid-{expids_str}_submove-{submove}.png')
    save_and_close_plot(fig, path)
    return path, msg

# read in the data files
input_data = {}
for path in infiles:
    this_data = read(path)
    input_data.update(this_data)
assert any(input_data), 'No data to analyze. Please check that input file args are correct.'

# containers / handlers for multiprocessed analysis data
results_list = []
stats_list = []
def store_result(result, stat, msg):
    if msg:
        print(msg)
    if result and stat:
        results_list.append(result)
        stats_list.append(stat)

single_process = args.n_processes_max == 1  # useful for debugging
if __name__ == '__main__':
    if single_process:
        for table in input_data.values():
            result = analyze(table)
            store_result(*result)
    else:
        with multiprocessing.Pool(processes=args.n_processes_max) as pool:
            pool_results = pool.imap(analyze, input_data.values())
            pool.close()
            pool.join()
        for result in pool_results:
            store_result(*result)
    results = vstack(results_list)
    stats = vstack(stats_list)
    petal_ids = set(results['PETAL_ID'])
    if single_process:
        for petal_id in petal_ids:
            submoves = set(results[results['PETAL_ID'] == petal_id]['SUBMOVE'])
            for submove in submoves:
                plot_petal(results, petal_id, submove)
    else:
        with multiprocessing.Pool(processes=args.n_processes_max) as pool:
            pass