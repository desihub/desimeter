#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Tool for analyzing positioner performance. Typically operates on data tables
retrieved using the "get_posmoves --with-calib" tool.
"""

# command line argument parsing
import argparse
parser = argparse.ArgumentParser(description=__doc__)
parser.add_argument('-i', '--infiles', type=str, required=True, nargs='*',
                    help='Path to input csv file(s), containing results from "get_posmoves --with-calib" ' +
                         '(see that function''s help for full syntax). Regex is ok (like M*.csv). Multiple ' +
                         'file args are also ok (like M00001.csv M00002.csv M01*.csv), as is a directory ' +
                         'that contains the files.')
parser.add_argument('-o', '--outdir', type=str, required=True, help='Path to directory where to save output files.')
parser.add_argument('-np', '--n_processes_max', type=int, default=None,  help='max number of processors to use')
args = parser.parse_args()

# proceed with bulk of imports
import os
import glob
import numpy as np
import math
from astropy.table import Table, vstack
from astropy.time import Time
from astropy.visualization import hist
from astropy.stats import knuth_bin_width
import desimeter.transform.pos2ptl as pos2ptl
import matplotlib.pyplot as plt
from matplotlib.ticker import FormatStrFormatter
import multiprocessing

# set up logger
import logging
log_level = logging.INFO + 1
log_handler = logging.StreamHandler()
log_formatter = logging.Formatter('%(asctime)s | %(message)s', datefmt='%Y-%m-%d %I:%M:%S %p')
log_handler.setFormatter(log_formatter)
logger = multiprocessing.get_logger()
logger.setLevel(log_level)
for handler in logger.handlers:
    logger.removeHandler(handler)
logger.addHandler(log_handler)
log = lambda msg, *args, **kwargs: logger.log(log_level, msg, *args, **kwargs)

# start runtime timer
start_time = Time.now()

# paths
infiles = []
for s in args.infiles:
    these = glob.glob(s)
    for this in these:
        if os.path.isdir(this):
            contents = os.listdir(this)
            contents = [os.path.join(this, file) for file in contents]
            infiles.extend(contents)
        else:
            infiles.append(this)
infiles = [os.path.realpath(p) for p in infiles]
save_dir = os.path.realpath(args.outdir)
if not os.path.isdir(save_dir):
    os.path.os.makedirs(save_dir)
img_format = 'png'  # for plot outputs

# data identifiers and keywords
required = {'PETAL_ID', 'POS_ID', 'POS_MOVE_INDEX', 'POS_T', 'POS_P', 'PTL_X', 'PTL_Y',
            'LENGTH_R1', 'LENGTH_R2', 'OFFSET_X', 'OFFSET_Y', 'OFFSET_T', 'OFFSET_P',
            'MOVE_CMD', 'EXPOSURE_ID', 'EXPOSURE_ITER', 'DEVICE_LOC', 'DATE', 'LOG_NOTE'}
sequence_note_prefix = 'sequence: '

# statistics functions for summarizing errors
stat_funcs = {'max': np.max, 'min': np.min, 'mean': np.mean, 'median': np.median,
              'std': np.std, 'rms': lambda X: np.sqrt(np.sum(np.power(X, 2))/len(X))}

# function defs
def nulls(*args):
    '''Returns set of indexes for null entries in one or more argued arrays.'''
    special_null_cases = {'None', 'none', '(null)', 'null'}
    idxs = set()
    for array in args:
        idxs |= {i for i in range(len(array)) if not(array[i]) or array[i] in special_null_cases}
    return idxs

def tokenize_note(log_note):
    '''Returns list of tokens in a LOG_NOTE entry.'''
    tokens = log_note.split(';')
    tokens = [token.strip() for token in tokens]
    return tokens

def parse_val(string, separator=' ', typefunc=int):
    '''Parse a number out of typical token format from LOG_NOTE strings.'''
    split = string.split(separator)
    val = typefunc(split[1]) if len(split) > 0 else None
    return val

def remove_nonmoving_rows(table):
    '''Deletes rows with no move.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  new ... copy of table, with equal or fewer rows
    '''
    new = table.copy()
    null_check_cols = ['MOVE_CMD', 'PTL_X', 'PTL_Y', 'EXPOSURE_ID']
    null_check_arrays = [new[key].tolist() for key in null_check_cols]
    null_idxs = nulls(*null_check_arrays)
    exp_iters = new['EXPOSURE_ITER'].tolist()  # special handling because value of 0 is ok
    null_iters = {i for i in nulls(exp_iters) if exp_iters[i] != 0}
    null_idxs |= null_iters
    new.remove_rows(list(null_idxs))
    return new

def remove_unused_columns(table):
    '''Deletes unnecessary columns, for easier data viewing.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  new ... copy of table, with equal or fewer columns
    '''
    new = table.copy()
    useless = set(new.columns) - required
    new.remove_columns(list(useless))
    return new

def read(path):
    '''Read in data from disk. If data has multiple posids, their respective data
    will be returned in multiple tables.
    
    Basic validation that the required data exists will be performed. This includes
    checking that the data includes actual moves. Thus the function is tolerant of
    data files for non-moving positioners --- they will be automatically skipped.
    
    INPUTS:  path ... must be a csv file, including move and calibration data
    
    OUTPUT:  data ... dict with keys = posids and values = astropy tables
    '''
    data = {}
    if 'csv' not in path:
        return data  # i.e. skip non-data files
    table = Table.read(path)
    missing = required - set(table.columns)
    if any(missing):
        log(f'Skipped data at {path} due to missing columns {missing}')
        return data
    initial_posids = set(table['POS_ID'])
    table = remove_unused_columns(table)
    table = remove_nonmoving_rows(table)
    posids = set(table['POS_ID'])
    posids_removed = initial_posids - posids
    if any(posids_removed):
        log(f'Skipped data for {posids_removed} which contained no moves in {path}')
    for posid in posids:
        selection = table['POS_ID'] == posid
        this = table[selection]
        data[posid] = this
        log(f'Read data for {posid} at {path}')
    return data

def identify_submoves(table):
    '''Searches LOG_NOTE field to identify submoves (i.e. correction moves).
    
    INPUTS:  table ... astropy table containing 'LOG_NOTE' and 'EXPOSURE_ID'
    OUTPUT:  copy of table, with new columns 'MOVE' and 'SUBMOVE', containing
             integer IDs identifying any moves and submoves.
             
    Note that 'MOVE' values may not be unique, if the dataset includes multiple
    tests. In such cases, uniqueness can be determined by inspecting also the
    EXPOSURE_ID field --- within which MOVE *will* be unique.
    
    Additionally, note that 'MOVE' integers may not correspond 1:1 with those
    given in the LOG_NOTE fields, again due to handling of uniqueness corner
    cases. However, 'SUBMOVE' ids *will* correspond exactly to those in LOG_NOTE.
    '''
    new = table.copy()
    new.sort('POS_MOVE_INDEX')
    move_counter = -1
    moves = []
    submoves = []
    last_expid = new['EXPOSURE_ID'][0]
    last_named_move = None  # different from move_counter ... this is from LOG_NOTE field
    for i in range(len(new)):
        expid = new['EXPOSURE_ID'][i]
        if expid != last_expid:
            move_counter = -1
            last_expid = expid
        note = new['LOG_NOTE'][i]
        if 'submove' not in note:
            move_counter += 1
            submove = 0
        else:
            tokens = tokenize_note(note)
            found_move, found_submove = False, False
            for token in tokens:
                if token.find('move') == 0:
                    named_move = parse_val(token)
                    found_move = True
                if token.find('submove') == 0:
                    submove = parse_val(token)
                    found_submove = True
            assert found_move and found_submove, f'move/submove parsing error of LOG_NOTE: {note}'
            if named_move != last_named_move:
                move_counter += 1
                last_named_move = named_move
        moves.append(move_counter)
        submoves.append(submove)
    new['MOVE'] = moves
    new['SUBMOVE'] = submoves
    return new

def get_submove_idxs(table, submove):
    '''Returns a list of idxs for rows associated with the argued submove.
    
    INPUT:  table ... astropy table including column 'SUBMOVE'
            submove ... integer
            
    OUTPUT: list of row index integers
    '''
    selection = table['SUBMOVE'] == submove
    sel_idxs = [selection[i] for i in range(len(table))]
    return sel_idxs

def get_sigma_idxs(table, sigma):
    '''Returns a list of idxs for data rows at or above a given sigma quantile.
    
    INPUT:  table ... astropy table including column 'SIGMA_GROUP'
            sigma ... like 1, 2, 3, ... math.inf or np.inf are also valid
            
    OUTPUT: list of row index integers
    '''
    selection = table['SIGMA_GROUP'] <= sigma
    sel_idxs = [selection[i] for i in range(len(table))]
    return sel_idxs

def get_submove_ids(table):
    '''Returns a sorted list of submove ids.
    INPUT:  table ... astropy table including column 'SUBMOVE'
    OUTPUT: list
    '''
    return sorted(set(table['SUBMOVE']))

def get_sigmas(table):
    '''Returns a dict with keys = 'SIGMA_GROUP' and values = corresponding 'QUANTILE_GROUP'
    '''
    sigmas = sorted(set(table['SIGMA_GROUP']))
    return {s: table['QUANTILE_GROUP'][table['SIGMA_GROUP'] == s][0] for s in sigmas}    

def calc_errors(table):
    '''Identifies measured and target values, then calculates errors.
    
    INPUTS:  table ... astropy table containing 'PTL_X', 'PTL_Y', 'POS_T', 'POS_P',
                       'LENGTH_R1', 'LENGTH_R2', 'OFFSET_T', 'OFFSET_P', 'OFFSET_X',
                       'OFFSET_Y', 'SUBMOVE', and 'POS_MOVE_INDEX'
    OUTPUT:  copy of table, where measured data columns will have _MEAS  appended to
             their names (for clarity) and new columns will be added with _TARG suffix,
             as well as new columns with ERR_ prefix
    '''
    new = table.copy()
    new.sort('POS_MOVE_INDEX')
    for key in ['PTL_X', 'PTL_Y', 'PTL_Z', 'OBS_X', 'OBS_Y']:
        if key in new.columns:
            new.rename_column(key, f'{key}_MEAS')
    meas_x, meas_y = new['PTL_X_MEAS'], new['PTL_Y_MEAS']
    targ_x, targ_y = pos2ptl.int2ptl(t_int=new['POS_T'], p_int=new['POS_P'],
                                     r1=new['LENGTH_R1'], r2=new['LENGTH_R2'],
                                     t_offset=new['OFFSET_T'], p_offset=new['OFFSET_P'],
                                     x_offset=new['OFFSET_X'], y_offset=new['OFFSET_Y'])
    is_submove0 = new['SUBMOVE'] == 0
    targ_xy = [targ_x, targ_y]
    for i in [0, 1]:
        last_targ0 = targ_xy[i][0]
        for j in range(len(targ_xy[i])):
            if is_submove0[j]:
                last_targ0 = targ_xy[i][j]
            else:
                targ_xy[i][j] = last_targ0
    new['PTL_X_TARG'] = targ_x
    new['PTL_Y_TARG'] = targ_y
    new['ERR_X'] = meas_x - targ_x
    new['ERR_Y'] = meas_y - targ_y
    new['ERR_XY'] = np.hypot(new['ERR_X'], new['ERR_Y'])
    return new

def calc_loc(table):
    '''Adds columns for "LOC" coordinates, matching any prefixed with "PTL".
    '''
    new = table.copy()
    suffixes = [col.split('PTL_X')[1] for col in table.columns if col.find('PTL_X') == 0]
    for suffix in suffixes:
        x_flat, y_flat = pos2ptl.ptl2flat(x_ptl=new['PTL_X' + suffix],
                                          y_ptl=new['PTL_Y' + suffix])
        x_loc = pos2ptl.flat2loc(x_flat, new['OFFSET_X'])
        y_loc = pos2ptl.flat2loc(y_flat, new['OFFSET_Y'])
        new['LOC_X' + suffix] = x_loc
        new['LOC_Y' + suffix] = y_loc
    return new

null_num_images = -1
def detect_num_fvc_images(table):
    '''Where possible, identifies how many images were taken per measurement.
    
    INPUT:  table ... astropy table including columns 'EXPOSURE_ID' and 'EXPOSURE_ITER'
    
    OUTPUT: copy of table, with new column NUM_IMAGES, whose values are ints. Where
            unknown, the value will be -1
    '''
    new = table.copy()
    new.sort(keys=['EXPOSURE_ID', 'EXPOSURE_ITER'])
    num_images = [null_num_images] + np.diff(new['EXPOSURE_ITER']).tolist()
    new['NUM_IMAGES'] = num_images
    zeroth_exp_iters = new['EXPOSURE_ITER'] == 0
    new['NUM_IMAGES'][zeroth_exp_iters] = null_num_images
    return new

def calc_target_radii(table):
    '''Calculates local radius of each target from its positioner's center.
    
    INPUT:  table ... astropy table including columns 'LOC_X_TARG' and 'LOC_Y_TARG'
    
    OUTPUT: copy of table, adding column 'TARGET_RADIUS'
    '''
    new = table.copy()
    radii = np.hypot(table['LOC_X_TARG'], table['LOC_Y_TARG'])
    new['TARGET_RADIUS'] = radii
    return new
    
def analyze_one_pos(table):
    '''Analyze the data for one table, containing one positioner's data.
    
    INPUTS:  table ... astropy table, as generated by read()
    OUTPUT:  (new, stats)
    
    "new" is an astropy table, containing data copied from "table", as well as some
    new columns like calculated error values.
    
    "stats" is another  astropy table, containing summary error statistics for
    each submove in "table".
    '''
    new = table.copy()
    new.sort('POS_MOVE_INDEX')
    posids = set(new['POS_ID'])
    assert len(posids) == 1, f'error: input to analyze should be a table with only one posid, not {posids}'
    posid = posids.pop()
    new = identify_submoves(new)
    new = calc_errors(new)
    new = calc_loc(new)
    new = calc_target_radii(new)
    new = detect_num_fvc_images(new)
    stats_cols = ['POS_ID', 'SUBMOVE', 'N_TARGETS'] + list(stat_funcs)
    stats_dict = {name:[] for name in stats_cols}
    submoves = get_submove_ids(new)
    for submove in submoves:
        selection = get_submove_idxs(new, submove)
        err_xy = new['ERR_XY'][selection].tolist()
        stats_dict['POS_ID'].append(posid)
        stats_dict['SUBMOVE'].append(submove)
        stats_dict['N_TARGETS'].append(len(err_xy))
        for name, func in stat_funcs.items():
            stats_dict[name].append(func(err_xy))
    stats = Table(stats_dict)
    log(f'Analyzed {posid}: {len(new)} data rows, {len(submoves)} submoves')
    return new, stats

def identify_quantiles(table, sigmas=[1,2,3,4,5,math.inf]):
    '''Gathering positioners into error quantiles at the specified "sigma" levels.
    Quantile assignments are done independently for each submove.
    
    INPUTS:  table ... astropy table with data for one or many positioners. The table
                       must include the columns 'ERR_XY' and 'SUBMOVE'
                       
             sigmas ... list of ints giving which sigma quantiles to gather the data
                        into. In other words, sigma=1 corresponds to 63.2% quantile,
                        sigma=2 corresponds to 86.5%, etc. A value math.inf or np.inf
                        acts like a "100%" quantile.
                        
    OUTPUTS: new ... copy of table, with additional columns 'SIGMA_GROUP' and
                     'QUANTILE_GROUP'. These correspond to the lowest quantile
                     group in which each error value resides.
    '''
    new = table.copy()
    new['SIGMA_GROUP'] = math.inf
    new['QUANTILE_GROUP'] = 1.0
    submoves = get_submove_ids(new)
    sigmas = sorted(sigmas, reverse=True)  # start with narrowest group (largest sigma), then broaden
    quantiles = {s: 1 - math.exp(-s) for s in sigmas}
    for submove in submoves:
        submove_selection = new['SUBMOVE'] == submove
        for sigma in sigmas:
            quantile = quantiles[sigma]
            cutoff = np.quantile(new['ERR_XY'][submove_selection], quantile, interpolation='midpoint')
            within_cutoff = new['ERR_XY'] <= cutoff
            quantile_selection = np.logical_and(within_cutoff, submove_selection)
            new['SIGMA_GROUP'][quantile_selection] = sigma
            new['QUANTILE_GROUP'][quantile_selection] = quantile
    return new

def summarize_stats(table, stat_names=stat_funcs.keys()):
    '''Generate summary statistics for each submove.
    
    INPUTS:  table ... astropy table with data for one or many positioners. The table
                       must include columns for 'SUBMOVE', 'POS_ID', 'ERR_XY',
                       'NUM_IMAGES', 'TARGET_RADIUS', 'SUBMOVE_SIGMA_GROUP', and
                       'SUBMOVE_QUANTILE_GROUP'
                        
             stat_names ... names of which stat_funcs results to perform the quantiles
                            on. Must be a subset of stat_funcs.
    
    OUTPUTS: new ... astropy table with columns 'SUBMOVE', 'SIGMA', 'QUANTILE', 'N_TARGETS'
                     and columns corresponding to the uppercased names of the argued
                     stats functions. Table includes metadata: n_positioners, n_targets
    '''
    missing_funcs = set(stat_names) - set(stat_funcs)
    assert not(any(missing_funcs)), f'undefined stat funcs {missing_funcs}'
    uppercase_names = {key: key.upper() for key in stat_names}
    submoves = get_submove_ids(table)
    new_columns = ['SUBMOVE', 'SIGMA', 'QUANTILE', 'N_TARGETS'] + list(uppercase_names.values())
    new_dict = {key:[] for key in new_columns}
    sigmas = get_sigmas(table)
    max_radius = -math.inf
    min_radius = math.inf
    for submove in submoves:
        submove_selection = get_submove_idxs(table, submove)
        radii = table['TARGET_RADIUS'][submove_selection].tolist()
        max_radius = max(max_radius, max(radii))
        min_radius = min(min_radius, min(radii))
        for sigma in sigmas:
            quantile = sigmas[sigma]
            within_quantile = table['QUANTILE_GROUP'] <= quantile
            quantile_selection = np.logical_and(within_quantile, submove_selection)
            err = table['ERR_XY'][quantile_selection].tolist()
            new_dict['SUBMOVE'].append(submove)
            new_dict['SIGMA'].append(sigma)
            new_dict['QUANTILE'].append(quantile)
            new_dict['N_TARGETS'].append(len(err))
            for name in stat_names:
                func = stat_funcs[name]
                stat_result = func(err)
                key = uppercase_names[name]
                new_dict[key].append(stat_result)    
    num_images = [n for n in table['NUM_IMAGES'] if n != null_num_images]
    mean_num_images = np.mean(num_images)
    new = Table(new_dict)
    new.meta['n_positioners'] = len(set(table['POS_ID']))
    new.meta['n_targets'] = len([x for x in table['SUBMOVE'] == sorted(submoves)[0] if x])
    new.meta['mean_num_images'] = mean_num_images
    new.meta['max_radius'] = max_radius
    new.meta['min_radius'] = min_radius
    return new

def meta_str(table):
    '''Produces a multi-line string representation of meta data in table.
    '''
    alts = {'n_positioners': 'Num positioners',
            'n_targets': 'Total num targets',
            'mean_num_images': 'Mean num images per meas',
            'max_radius': 'Max target radius (mm)',
            'min_radius': 'Min target radius (mm)'}
    formats = {'mean_num_images': '.1f', 'max_radius': '.3f', 'min_radius': '.3f'}
    s = ''
    for key, val in table.meta.items():
        name = alts[key] if key in alts else key
        if key in formats:
            val = format(val, formats[key])
        s += f'{name}: {val}\n'
    return s

def get_summary_stats_str(table, submove='all'):
    '''Produces a multi-line string representation of summary statistics
    
    INPUT:  table ... astropy table as-generated by summarize_stats()
            submove ... 'all' or integer
    
    OUTPUT: string
    '''
    int_list = lambda key: sorted([int(x) if x != math.inf else x for x in set(table[key])])
    submoves = int_list('SUBMOVE')
    if submove != 'all':
        assert submove in submoves
        submoves = [submove]
    sigmas = int_list('SIGMA')
    sigma_associates_list = lambda key: [table[key][table['SIGMA'] == s][0] for s in sigmas]
    quantiles = sigma_associates_list('QUANTILE')
    sigma_n_targs = sigma_associates_list('N_TARGETS')
    stat_names = [key for key in table.columns if key.lower() in stat_funcs]
    tab = '  '
    space = ' '
    unit = 'um'
    def row_str(arr, width=10, scale=1, suffix=''):
        cells = []
        adj_width = width - len(suffix)
        for x in arr:
            if isinstance(x, (int, np.integer, str)):
                cells.append(format(x, f'>{adj_width}') + str(suffix))
            else:
                cells.append(format(x*scale, f'>{adj_width}.1f') + str(suffix))
        out = space.join(cells)
        out += '\n'
        return out
    s = ''
    left_cell = lambda string: f'{tab}{string:>13}:'
    s += left_cell('sigma') + row_str(sigmas)
    s += left_cell('% of targets') + row_str(quantiles, scale=100, suffix='%')
    s += left_cell('num targets') + row_str(sigma_n_targs)
    for submove in submoves:
        prefix = f'SUBMOVE {submove} '
        for name in stat_names:
            selection = get_submove_idxs(table, submove)
            subtable = table[selection]
            selections = [subtable['SIGMA'] == sig for sig in sigmas]
            row_data = [subtable[name][sel][0] for sel in selections]
            s += left_cell(prefix + name) + row_str(row_data, scale=1000)
            prefix = '... '
    row_widths = [len(x) for x in s.split('\n')]
    header = f'Positioning errors summary (distance units = {unit}):'
    s = format(header, f'<{max(row_widths)}') + '\n' + s
    return s

default_plot_limits = {'xfig': 10, 'yfig': 8, 'dpi': 150}  # xfig and yfig are in inches

def init_plot(limits=default_plot_limits):
    '''Initialize a plot.
    INPUT:  limits ... dict with keys 'xfig', 'yfig', 'dpi'
    OUTPUT: Returns figure handle
    '''
    plt.ioff()
    fig = plt.figure(figsize=(limits['xfig'], limits['yfig']), dpi=limits['dpi'])
    plt.clf()
    return fig

def finalize_plot(savepath, limits={}):
    '''Updates plot limits (if necessary) and saves current plot to disk. Then
    closes it.
    
    INPUT:  savepath ... where to save the image. Extension determines image format
            limits ... dict that optionally includes keys 'xlim', 'ylim' for an xy plot
                       or 'xlim', 'bins' for a histogram
            
    OUTPUT: updated limits dict, containing entries for the current plot xlim and ylim
    '''
    fig = plt.gcf()
    if 'xlim' in limits:
        plt.xlim(limits['xlim'])
    if 'ylim' in limits:
        plt.ylim(limits['ylim'])
    limits['xlim'] = plt.xlim()
    if 'bins' not in limits:  # i.e. skip this if it's a histogram
        limits['ylim'] = plt.ylim()
    fig.tight_layout()
    plt.savefig(savepath, bbox_inches='tight')
    plt.close(fig)
    return limits
    
def get_span(table, prefix='PTL_X'):
    '''Returns max - min for all measured and target 'PTL_X' or 'PTL_Y' data in table.'''
    vec = table[f'{prefix}_TARG'].tolist() + table[f'{prefix}_MEAS'].tolist()
    return max(vec) - min(vec)

def get_expids_str(table, for_filename=True):
    '''Returns a string representing the set of unique 'EXPOSURE_ID' in the astropy
    table. Argument for_filename controls whether to return version for use in
    filenames vs for use in plot labels, general printouts, etc.
    '''
    expids = sorted(set(table['EXPOSURE_ID']))
    separator = '-' if for_filename else ','
    expids_str = separator.join([str(x) for x in expids])
    return expids_str

def get_submoves_str(table, for_filename=True):
    '''Returns a string representing the set of unique 'SUBMOVE' in the astropy
    table. Argument for_filename controls whether to return version for use in
    filenames vs for use in plot labels, general printouts, etc.'''
    submoves = get_submove_ids(table)
    separator = '-' if for_filename else ', '
    plural = 's' if len(submoves) > 1 else ''
    valstr = str(submoves[0]) if len(submoves) > 1 else separator.join([str(s) for s in submoves])
    if for_filename:
        return valstr
    return f'Submove{plural}: {valstr}'

def get_sigma_str(table, for_filename=True):
    '''Returns a string representing the largest (i.e. broadest) value of 'SIGMA_GROUP'
    and 'QUANTILE_GROUP' in the astropy  table. Argument for_filename controls whether to
    return version for use in filenames vs for use in plot labels, general printouts, etc.'''
    sigmas = get_sigmas(table)
    sigma = max(sigmas.keys())
    quantile = sigmas[sigma]
    if for_filename:
        return f'{sigma:.1f}'
    return f'Sigma: {sigma:.1f} ({quantile*100:.3g}%)'

def get_exposure_description(table):
    '''Returns a multiline string describing some general info about the exposure(s)
    represented in the table data.
    
    INPUT:  table ... astropy tabel including 'DATE' and 'EXPOSURE_ID' columns
    
    OUTPUT: string
    '''
    dates = {d.split(' ')[0] for d in table['DATE']}
    dates = sorted(dates)
    expids_str = get_expids_str(table, for_filename=False)
    s = f'Exposure ID{"s" if "," in expids_str else ""}: {expids_str}\n'
    s += f'Date{"s" if len(dates) > 1 else ""} measured: {dates if len(dates) > 1 else dates[0]}\n'
    s += f'Date analyzed: {Time.now().iso.split(" ")[0]}'
    return s

def get_description(table, column, value):
    '''Returns a multiline string describign some general info about those rows
    for which value in column matches val.
    
    INPUT:  table ... astropy table including column key
            column ... 'SUBMOVE' or 'SIGMA_GROUP'
            value ... single value or 'all' to describe all unique cases found in column
            
    OUTPUT: string
    '''
    if value == 'all':
        selection = list(range(len(table)))
    elif column == 'SUBMOVE':
        selection = get_submove_idxs(table, value)
    elif column == 'SIGMA_GROUP':
        selection = get_sigma_idxs(table, value)
    subtable = table[selection]
    if column == 'SUBMOVE':
        return get_submoves_str(subtable, for_filename=False)
    elif column == 'SIGMA_GROUP':
        return get_sigma_str(table, for_filename=False)
        
def get_submove_description(table, submove='all'):
    return get_description(table, 'SUBMOVE', submove)

def get_sigma_description(table, sigma='all'):
    return get_description(table, 'SIGMA_GROUP', sigma)

def place_notes(note1='', note2=''):
    '''Puts note strings on the current plot.
    '''
    note_fontsize = 'small'
    vert_space = ''.join(['\n']*5)
    note_kwargs = {'xycoords': 'axes fraction', 'fontfamily': 'monospace',
                   'fontsize': note_fontsize, 'verticalalignment': 'top'}
    for note, special in {note1: {'xy': (0.00, 0.0), 'horizontalalignment': 'left'},
                          note2: {'xy': (0.99, 0.0), 'horizontalalignment': 'right'},
                          }.items():
        note = vert_space + note
        note = strip_final_return(note)
        note_kwargs.update(special)
        if note:
            plt.annotate(note, **note_kwargs)

def bigchart(table, note1='', note2='', limits={}):
    '''Plot all targets and measurements for positioners on one big chart.
    
    INPUT:  table ... astropy table including 'PTL_X_MEAS', 'PTL_Y_MEAS', 'PTL_X_TARG',
                      'PTL_Y_TARG', 'POS_ID', 'DEVICE_LOC', 'EXPOSURE_ID'
            note1 ... optional multi-line string, to be printed at bottom of chart
            note2 ... optional multi-line string, to be printed at bottom of chart
            limits ... optionally can force plot limits (e.g. to homogenize plots
                       for multiple submoves). format is a dict with keys: 'xlim',
                       'ylim', 'xfig', 'yfig', and 'dpi'. xfig and yfig are in inches
            
    OUTPUT: path ... path to output plot file
            limits ... dict of same format as described above
    '''
    if not limits:
        dpi = 200
        min_plot_dims = (10, 8)
        dots_per_mm = 12
        data_span_mm = [get_span(table, 'PTL_X'), get_span(table, 'PTL_Y')]
        fig_size_in = [mm * dots_per_mm / dpi for mm in data_span_mm]
        fig_size_in = [max(fig_size_in[i], min_plot_dims[i]) for i in [0,1]]
        fig_size_in[1] += 2
        limits = {'xfig': fig_size_in[0], 'yfig': fig_size_in[1], 'dpi':dpi}
    init_plot(limits)
    for suffix, desc in {'TARG':'target', 'MEAS':'measured'}.items():
        shape = 'o' if suffix == 'TARG' else '+'
        plt.plot(table[f'PTL_X_{suffix}'], table[f'PTL_Y_{suffix}'], shape, label=desc)
    posids = set(table['POS_ID'])
    for posid in posids:
        selection = table['POS_ID'] == posid
        label_x = np.mean(table['PTL_X_TARG'][selection])
        label_y = np.mean(table['PTL_Y_TARG'][selection])
        loc = table['DEVICE_LOC'][selection][0]
        label_text = f'{posid}\n({loc})'
        plt.annotate(label_text, xy=(label_x, label_y), xycoords='data', 
                     horizontalalignment='center', verticalalignment='top',
                     fontfamily='monospace', fontsize='small')
    plt.xlabel('PTL_X (mm)')
    plt.ylabel('PTL_Y (mm)')
    place_notes(note1, note2)
    plt.legend(loc='upper left')
    plt.axis('equal')
    expids_str = get_expids_str(table, for_filename=True)
    path = os.path.join(save_dir, f'expid_{expids_str}_chart_submove_{submove}.' + img_format)
    limits = finalize_plot(path, limits)
    return path, limits

def histogram(table, note1='', note2='', limits={}):
    '''Make a histogram of positioning errors.
    
    INPUT:  table ... astropy table including 'ERR_XY' and 'SUBMOVE'
            note1 ... optional multi-line string, to be printed at bottom of chart
            note2 ... optional multi-line string, to be printed at bottom of chart
            limits ... optionally can force plot limits (e.g. to homogenize plots
                       for multiple submoves). format is a dict with keys: 'xlim',
                       'bins', 'xfig', 'yfig', and 'dpi'. xfig and yfig are in inches
            
    OUTPUT: path ... path to output plot file
            limits ... dict of same format as described above
    '''
    if not limits:
        limits = {'xfig': 9.5, 'yfig': 7, 'dpi': 200}
    init_plot(limits)
    scale = 1000
    n_bins_min = 20
    data = table['ERR_XY'] * scale
    if 'bins' in limits:
        bins = limits['bins']
    else:
        bins = knuth_bin_width(data, return_bins=True)[1]
        bins = max(len(bins), n_bins_min)
    label = get_sigma_str(table, for_filename=False)
    _, bins, _ = hist(data, bins=bins, max_bins=1000, label=label)
    limits['bins'] = bins
    mean = np.mean(data)
    plt.plot([mean, mean], plt.ylim(), 'r--', label='mean')
    plt.xlabel('XY ERROR (um)')
    plt.legend(loc='upper right')
    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.0f'))
    place_notes(note1, note2)    
    expids_str = get_expids_str(table, for_filename=True)
    sigma = get_sigma_str(table, for_filename=True)
    path = os.path.join(save_dir, f'expid_{expids_str}_hist_sigma_{sigma}.' + img_format)
    limits = finalize_plot(path, limits)
    return path, limits

def strip_final_return(string):
    '''Remove final carriage return if present.'''
    return string[:-1] if string[-1] == '\n' else string

# single/multiprocess switching
single_process = args.n_processes_max == 1  # useful for debugging
def imap(function, iterable_data):
    '''Common wrapper for pooled single or multiprocess imap'''
    if single_process:
        results = []
        for data in iterable_data:
            result = function(data)
            results.append(result)
    else:
        with multiprocessing.Pool(processes=args.n_processes_max) as pool:
            results = pool.imap(function, iterable_data)
            pool.close()
            pool.join()
    return results
            
if __name__ == '__main__':
    
    # read data
    input_data = {}
    results = imap(read, infiles)
    for result in results:
        input_data.update(result)
    assert any(input_data), 'No data to analyze. Please check that input file args are correct.'
    
    # analyze individual positioners
    moves_list = []
    stats_list = []
    results = imap(analyze_one_pos, input_data.values())
    for result in results:
        move, stat = result
        if result and stat:
            moves_list.append(move)
            stats_list.append(stat)
            
    # merge results
    moves = vstack(moves_list)
    stats = vstack(stats_list)
    
    # binning
    moves = identify_quantiles(moves)
    summary = summarize_stats(moves)
    
    # plot big xy charts
    chart_limits = {}
    submoves = get_submove_ids(moves)
    for submove in submoves:
        submove_selection = get_submove_idxs(moves, submove)
        table = moves[submove_selection]
        note1 = get_submove_description(table, submove)
        note1 += '\n' + get_exposure_description(table)
        note1 += '\n' + meta_str(summary)
        note2 = get_summary_stats_str(summary, submove)
        path, chart_limits = bigchart(table, note1, note2, chart_limits)
        log(f'Saved big chart for submove {submove} to {path}')
    
    # plot histograms
    hist_limits = {}
    sigmas = get_sigmas(moves)
    for sigma in sigmas:
        sigma_selection = get_sigma_idxs(moves, sigma)
        subtable = moves[sigma_selection]
        note1 = get_sigma_description(subtable)
        note1 += '\n' + get_submove_description(subtable)
        note1 += '\n' + get_exposure_description(subtable)
        note1 += '\n' + meta_str(summary)
        note2 = ''
        path, hist_limits = histogram(subtable, note1, note2, hist_limits)
        log(f'Saved histogram for sigma={sigma} to {path}')
        
    # export tabular data
    expids_str = 'expid_' + get_expids_str(moves, for_filename=True)
    moves_path = os.path.join(save_dir, f'{expids_str}_moves.csv')
    stats_path = os.path.join(save_dir, f'{expids_str}_stats_by_positioner.csv')
    summary_path_base = os.path.join(save_dir, f'{expids_str}_stats_summary')
    moves.write(moves_path, overwrite=True)
    log(f'Saved move-by-move data table to {moves_path}')
    stats.write(stats_path, overwrite=True)
    log(f'Saved positioner-by-positioner performance stats to {stats_path}')
    ecsv_path = summary_path_base + '.ecsv'
    summary.write(ecsv_path, overwrite=True, delimiter=',')
    log(f'Saved overall summary stats + metadata to {ecsv_path}')
    csv_path = summary_path_base + '.csv'
    summary.write(csv_path, overwrite=True)
    log(f'Saved overall summary stats (no metadata) to {csv_path}')
    runtime = (Time.now() - start_time).to_value('sec')
    runtime_str = f'{runtime:.1f} sec' if runtime < 60 else f'{runtime/60:.1f} min'
    log(f'Total run time: {runtime_str}')
    