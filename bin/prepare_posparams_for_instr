#!/usr/bin/env python
# -*- coding: utf-8 -*-

import time
filename_timestamp_format = '%Y%m%dT%H%M%S%z'
output_prefix = time.strftime(filename_timestamp_format, time.gmtime())
output_suffix = '_posparams_for_instr'
output_name = output_prefix + output_suffix + '.csv'
log_name = output_prefix + output_suffix + '.log'
disable_key = 'DEVICE_CLASSIFIED_NONFUNCTIONAL'
disable_rationale_key = 'ENABLE_DISABLE_RATIONALE'
commit_prefix = 'COMMIT_'

set_enabling_docstr = f'''
    1. When set-enabling == False (default):
    ----------------------------------------
    Positioners which fail the fit error threshold check will simply be removed
    from the output file. Thus no changes will be pushed to DB for these. This is
    the appropriate behavior, for example, if the fit fails due to a math error,
    noise, or bad measurement data.
    
    2. When set-enabling == True (command-line option '-e'):
    --------------------------------------------------------
    Output file will include a column {disable_key}. This will
    contain True/False values reflecting pass/fail of the fit error threshold test.
    The script set_calibrations.py can subsequently batch enable or disable positioners
    accordingly. (Note: Like all the other parameters, you will *additionally* be
    offered a redundant option to set {commit_prefix + disable_key} to False,
    which *prevents* any enable/disable action from being actually performed.)
'''

__doc__ = f'''
Inspects paramfits csv table and prepares a version of the table which is
ready for operational use on the focal plane.

Output csv file will be named like "{output_name}", along with a similarly-
named text log file.

As of this writing (2020-06-12) the typical sequence is:
    
    1. get_posmoves ... get tracked (t,p) and measured (x,y) from online DB
    2. fit_posparams ... best-fit calib params which map (t,p) to (x,y)
    3. merge_posparams ... gather fit result files into one table
    4. prepare_posparams_for_instr ... THIS SCRIPT, generates modified table
    5. set_calibrations.py ... (managed in SVN) push data to the online DB
    
See DESI-5732 for data model and procedures.

Important note regarding '--set-enabling' ('-e') argument:
{set_enabling_docstr}
'''

force_no_scale = True
force_scale_explanation = '''
Note: As of 2020-06-16, we are not allowing SCALE_T and SCALE_P to be changed
in the online DB. The 'allow-scale' option will be ignored.

Implementation details: In the future, especially if we determine that some failed
positioners can be recovered this way, then the line force_no_scale would be
the first thing to change in the code. Then search for the uargs.allow_scale
property to find all the places you need to think about the SCALE issues.
'''

# command line argument parsing
import argparse
from argparse import RawTextHelpFormatter  # for making --help option respect newline characters
parser = argparse.ArgumentParser(description=__doc__, formatter_class=RawTextHelpFormatter)
parser.add_argument('-i', '--infile', type=str, required=True, help='path to input csv file (like "all_paramfits.csv")')
parser.add_argument('-e', '--set-enabling', action='store_true', help=f'set {disable_key} when checking fit error threshold')
parser.add_argument('-a', '--allow-scale', action='store_true', help='whether to allow updating of SCALE_T and SCALE_P, defaults to False')

uargs = parser.parse_args()
if force_no_scale and uargs.allow_scale:
    uargs.allow_scale = False
    print(force_scale_explanation)

# import data
from desimeter.posparams.movemask import movemask
from astropy.table import Table, Column
input_table = Table.read(uargs.infile)
new_table = input_table.copy()  # leave original input_table untouched in memory just for ease of comparison when debugging

# import other modules
import numpy as np
import os
import sys
from desimeter.log import get_logger
import desimeter.posparams.fitter as fitter
import desimeter.io

# set up a log file
script_name = os.path.basename(__file__)
out_dir = os.path.dirname(uargs.infile)
log_path = os.path.join(out_dir, log_name)
logger = get_logger(level=None, path=log_path, timestamps=True)
logger.info(f'Running {script_name} to prepare positioner calibration parameters for use on instrument.')
logger.info(f'Input file is: {uargs.infile}')
logger.info(f'Table contains {len(input_table)} rows')

# detect "static" and "dynamic" suffixes in data headers
# generate a key mapping for which of these options to push to the output table
keys_in_to_out = {}
for header in new_table.columns:
    keys_in_to_out[header] = header
    cases = {'STATIC': fitter.static_keys,
             'DYNAMIC': fitter.dynamic_keys}
    for case, case_keys in cases.items():
        for key in case_keys:
            match_found = header.find(key) == 0 and header.find(case) != -1
            if match_found:
                keys_in_to_out[header] = key
keys_out_to_in = {val:key for key,val in keys_in_to_out.items()}
for key_in, key_out in keys_in_to_out.items():
    new_table[key_out] = new_table[key_in]
    
# cast any boolean strings to true bools, where necessary
possible_bools = {'True', 'true', 'TRUE', True, 1, 'Yes', 'yes', 'YES'}
for key in new_table.columns:
    cast_as_boolean = commit_prefix in key or disable_key in key
    if cast_as_boolean:
        new = [True if x in possible_bools else False for x in new_table[key]]
        new_table[key] = new

# special setup for columns related to enabling/disabling
new_table[disable_key] = False
new_table[disable_rationale_key] = Column(['']*len(new_table), dtype=object) # astropy hack for variable length strings!
elim_action_str = 'marked' if uargs.set_enabling else 'excluded'

# user interaction wrappers
def input2(message):
    '''Wrapper for input which will log the interaction.'''
    logger.info(f'PROMPT: {message}')
    user_input = input('>>> ')
    if user_input == '':
        user_input = '(no entry)'
    logger.info(f'USER ENTERED >>> {user_input}')
    return user_input

blank_responses = {'', '(no entry)'}

def yesnohelp(message, yes=True, no=True, help_=True, exit_=True):
    '''Wrapper for user input which cleans up human-entered values and returns
    a string of exactly 'yes', 'no', or 'help'. Also can give user option to
    exit the program.
    
    Boolean args allow you to turn off options for the user.
    '''
    assert yes or no or help_ or exit_, 'need at least one user option'
    suffix_parts = ['y' if yes else None,
                    'n' if no else None,
                    'help' if help_ else None,
                    'exit' if exit_ else None,
                    ]
    suffix_parts = [s for s in suffix_parts if s]
    suffix = '/'.join(suffix_parts)
    answer =  input2(f'{message} ({suffix})')
    if help_ and answer.lower() in {'h', 'help', 'doc', 'man'}:
        return 'help'
    if no and answer.lower() in {'n', 'no', 'false'}:
        return 'no'
    if yes and answer.lower() in {'y', 'yes', 'true'}:
        return 'yes'
    if exit_ and answer.lower() in {'exit'}:
        logger.info('Exiting at user request.')
        sys.exit(0)
    return yesnohelp(message)

def str2float(s):
    '''Returns float, or None if string s can not be converted to float.'''
    try:
        x = float(s)
        assert np.isfinite(x)
        return x
    except:
        return None

def join_notes(*args):
    '''Concatenate items into a "note" string with standard format. A list or
    tuple arg is treated as a single "item". So for example if you want the
    subelements of a list "joined", then argue it expanded, like *mylist
    '''
    separator = '; '
    if len(args) == 0:
        return ''
    elif len(args) == 1:
        return str(args[0])
    strings = (str(x) for x in args if x != '')
    return separator.join(strings)

def _eliminate_rows(table, elim, rationale):
    '''Logs messages and returns a copy of table, with rows identified by elim
    either deleted from it or marked DEVICE_CLASSIFIED_NONFUNCTIONAL.
    
        table ... astropy table
        elim ... list of booleans saying whether to eliminate that row
                 must be same length as table
        rationale ... string message to include in log output message for any
                      rows with elim == True
    '''
    assert len(table) == len(elim), f'len(table)={len(table)} != len(elim)={len(elim)}'
    if not(any(elim)):
        return table.copy()
    elim_bool = [bool(x) for x in elim]  # guarantee a clean boolean format
    keep = [x == False for x in elim_bool]
    all_posids = set(table['POS_ID'])
    posids_remaining = set(table['POS_ID'][keep])
    posids_eliminated = all_posids - posids_remaining
    n_rows = len(table)
    n_elim_rows = len(np.flatnonzero(elim_bool))  # flatnonzero is like argwhere but better
    n_elim_posids = len(posids_eliminated)
    logger.warning(f'{n_elim_rows} of {n_rows} rows have {rationale}. These rows will be {elim_action_str} ' +
                   f'from the output table. Affected positioners are:\n{sorted(posids_eliminated)}' +
                   f'\nTotal {elim_action_str} = {n_elim_posids}' +
                   f'\nNot {elim_action_str} = {len(posids_remaining)}')
    output = table.copy()    
    if uargs.set_enabling:
        output[disable_key] |= elim_bool
        existing = output[disable_rationale_key].tolist()
        output[disable_rationale_key] = [join_notes(existing[i], rationale) if elim_bool else existing[i] for i in range(len(output))]
    else:
        output.remove_rows(elim_bool)
    return output

# eliminate any rows for which a required value is masked
required_keys = {'POS_ID', 'FLAGS', 'DEVICE_LOC', 'NUM_POINTS', 'DATA_END_DATE',
                 'FIT_ERROR_STATIC', 'NUM_POINTS_IN_FIT_STATIC',}
required_keys |= set(fitter.static_keys)
if uargs.allow_scale:
    required_keys |= {'FIT_ERROR_DYNAMIC', 'NUM_POINTS_IN_FIT_DYNAMIC'}
mask_table = new_table.mask
masked_list = mask_table['POS_ID']
for key in required_keys:
    masked_list |= mask_table[key]
new_table = _eliminate_rows(new_table, masked_list, 'paramfits file missing required value(s)')

# check functions
def check_flags(table):
    '''Inspects FLAGS field of fit results.
    '''    
    # Internal details: Returns a copy of table.
    new = table.copy()
    for flag in movemask.names():
        fail_list = [movemask[flag] & value for value in new['FLAGS']]
        new = _eliminate_rows(new, fail_list, f'flag {flag}')
    return new

def check_static_fit_bounds(table, tighten_factor):
    '''Searches for any cases of params pegged to fitter bounds. Operates only on
    "static" parameters. Such cases immediately indicate a bad fit. Argument
    'tighten_factor' is a float which gives you some braod control to deal
    with numeric errors. It tightens the acceptable bounds by a fraction. E.g.,
    for a range [0.0, 2.0], a tighten_factor of 0.1 would use range [0.2, 1.8] in
    the filter.
    '''    
    # Internal details: Returns a copy of table.
    below_key = 'below min'
    above_key = 'above max'
    new = table.copy()
    for param in fitter.static_keys:
        minmax = fitter.default_bounds[param]
        delta = max(minmax) - min(minmax)
        limits = {below_key: min(minmax) + delta*tighten_factor,
                  above_key: max(minmax) - delta*tighten_factor}
        operators = {below_key: np.less,
                     above_key: np.greater}
        for key, limit in limits.items():
            op = operators[key]
            fail_list = op(new[param], limit)
            new = _eliminate_rows(new, fail_list, f'{param} {key} bound = {limit}')
    return new

def check_xy_offsets(table, tol):
    '''Checks reasonableness of OFFSET_X and OFFSET_Y w.r.t. metrology values.
    Argument 'tol' is a value in mm. Rows outside this tolerance will be
    eliminated from the output.
    '''
    # Internal details: Returns a copy of table.
    new = table.copy()
    expected_centers = desimeter.io.load_nominal_positioner_locations()
    delete_idxs = set()
    for i in range(len(new)):
        device_selection = expected_centers['DEVICE_LOC'] == new['DEVICE_LOC'][i]
        for u in ['X', 'Y']:
            expected_key = u + '_FLAT'
            offset_key = 'OFFSET_' + u
            expected = float(expected_centers[device_selection][expected_key])
            offset = new[offset_key][i]
            err = offset - expected
            if abs(err) > tol:
                delete_idxs.add(i)
                logger.warning(f'Row for {new["POS_ID"][i]} {elim_action_str} due to {offset_key}=' +
                               f'{offset:.4f} outside tol={tol} of nominal {expected:.4f} ' +
                               f'by {offset-expected:.4f}')
    delete_bools = [i in delete_idxs for i in range(len(new))]
    new = _eliminate_rows(new, delete_bools, f'OFFSET_X or OFFSET_Y outside tol={tol} of nominal value')
    return new

def check_arm_lengths(table, tol):
    '''Checks closeness of LENGTH_R1 and LENGTH_R2 to their nominal values.
    Argument 'tol' is a value in mm. Rows outside this tolerance will be
    eliminated from the output.
    '''
    # Internal details: Returns a copy of table.
    new = table.copy()
    expected_lengths = {key: fitter.default_values[key] for key in ['LENGTH_R1', 'LENGTH_R2']}
    delete_idxs = set()
    for i in range(len(new)):
        for key, exp in expected_lengths.items():
            length = new[key][i]
            err = length - exp
            if abs(err) > tol:
                delete_idxs.add(i)
                logger.warning(f'Row for {new["POS_ID"][i]} removed due to {key}=' +
                               f'{length:.4f} outside tol={tol} of nominal={exp:.4f}' +
                               f' by {length-exp:.4f}')
    delete_bools = [i in delete_idxs for i in range(len(new))]
    new = _eliminate_rows(new, delete_bools, f'LENGTH_R1 or LENGTH_R2 outside tol={tol} of nominal value')       
    return new

def check_fit_error(table, tol, key):
    '''Checks overall goodness of fit for. Argument 'tol' is max value in rms mm.
    '''
    # Internal details:
    #     Returns a copy of table.
    #     key ... 'STATIC' or 'DYNAMIC'
    #     set_enabling ... True  --> usual behavior of eliminating rows if not within tol
    #                      False --> keep row and mark DEVICE_CLASSIFIED_NONFUNCTIONAL to
    #                                True or False depending on whether threshold was met
    new = table.copy()
    fit_err_key = 'FIT_ERROR_STATIC' if 'STATIC' in key else 'FIT_ERROR_DYNAMIC'
    fit_errs = new[fit_err_key]
    failures = fit_errs > tol
    if uargs.set_enabling:
        new[disable_key] = failures
        will_disable = set(new['POS_ID'][new[disable_key]])
        for row in new:
            action = f'{disable_key}={row[disable_key]} because'
            sign = '>' if row[disable_key] else '<='
            row[disable_rationale_key] = f'{action} {fit_err_key}={row[fit_err_key]:.6f} {sign} tol={tol}'
            if row[disable_key]:
                logger.warning(row[disable_rationale_key])
    else:
        for i in np.flatnonzero(failures):
            logger.warning(f'Row for {new["POS_ID"][i]} removed due to {fit_err_key}={fit_errs[i]} > tol={tol}')
        new.remove_rows(failures)
    if uargs.set_enabling:
        logger.warning(f'{len(will_disable)} positioners will have {disable_key} --> True')
    return new

def check_num_outliers(table, tol, key):
    '''Checks number of outliers that were discarded during the fit. Argument 'tol'
    is an integer >= 0, giving the max number of outliers allowed.
    '''
    # Internal details:
    #     Returns a copy of table.
    #     key ... 'STATIC' or 'DYNAMIC'
    assert key in ['STATIC', 'DYNAMIC']
    assert isinstance(tol, (int, float))
    assert 0 <= tol
    new = table.copy()
    num_points_in_fit_key = f'NUM_POINTS_IN_FIT_{key}'
    num_outliers_key = f'NUM_OUTLIERS_EXCLUDED_{key}'
    new[num_outliers_key] = new['NUM_POINTS'] - new[num_points_in_fit_key]
    exceeds_tol = new[num_outliers_key] > tol
    new = _eliminate_rows(new, exceeds_tol, f'number of outliers > {tol}')
    return new

def check_recent_rehome(table):
    '''Searches for "recent rehome" criterion. This indicates that OFFSET_T and
    OFFSET_P are ok for use on instrument.
    '''
    # Internal details: Returns a copy of table.
    # As of 2020-06-15, not implemented. The assumption is that fit_posparams
    # output file contains only good OFFSET_T, OFFSET_P, generated from an
    # assumed RECENT_REHOME==True data set. Hopefully in the future we can
    # develop a more direct check here.
    return table.copy()  # not yet implemented

def check_uniqueness(table):
    '''Searches for multiple rows with same POS_ID, and asks user to resolve
    any conflicts.
    '''
    # Internal details: Returns a copy of table.
    unique_posids = set(table['POS_ID'])
    new = table.copy()
    def get_row_idxs(table, posid):
        '''Because I have a mental block remembering that flatnonzero is like
        argwhere except better.'''
        return np.flatnonzero(table['POS_ID'] == posid)
    for posid in unique_posids:
        row_idxs = get_row_idxs(new, posid)
        if len(row_idxs) == 1:
            continue
        options = {}
        for i in range(len(row_idxs)):
            info_keys = ['NUM_POINTS', 'DATA_END_DATE', 'FIT_ERROR_STATIC',
                         'FIT_ERROR_DYNAMIC'] + list(fitter.all_keys)
            options[i] = {key: new[key][row_idxs[i]] for key in info_keys}
        msg = f'{posid} has multiple rows:\n'
        for i, vals in options.items():
            msg += f'\n{posid} option {i}:\n{vals}\n'
        logger.warning(msg)
        retry = True
        while retry:
            user_input = input2('Please select number for WHICH OPTION TO KEEP, ' +
                                'or IF ANY DOUBT, enter "skip".')
            if user_input.lower() in {'skip', 's'}:
                new.remove_rows(row_idxs)
                logger.info(f'All {len(row_idxs)} rows for {posid} skipped (removed from table)')
                retry = False
            elif user_input in {str(i) for i in options.keys()}:
                delete_idxs = row_idxs[row_idxs != int(user_input)]
                new.remove_rows(delete_idxs)
                logger.info(f'{len(delete_idxs)} rows for {posid} removed')
                n_remaining = len(get_row_idxs(new, posid))
                assert n_remaining == 1, f'unknown error with {posid} during check_uniqueness, {n_remaining} rows for it in table'
                retry = False
    new_unique_posids = set(new['POS_ID'])
    new_listed_posids = list(new['POS_ID'])
    assert len(new_unique_posids) == len(new_listed_posids), 'error, not all conflicts resolved by check_uniqueness'
    return new

class Check(object):
    '''Represents a check function plus arguments.
        func ... function handle
        kwargs ... keyword/args dict of inputs for that function
    '''
    def __init__(self, func, **kwargs):
        self.func = func
        self.kwargs = kwargs
    
    @property
    def name(self):
        return self.func.__name__
    
    @property
    def doc(self):
        wrapped = " ".join(self.func.__doc__.split())
        return f'{self.name}:\n{wrapped}'
    
    def run(self, table):
        '''Performs the check function on astropy table of parameters data.'''
        args_note = f' with args {self.kwargs}' if self.kwargs else ''
        logger.info(f'{self.name}: starting{args_note}')
        output = self.func(table=table, **self.kwargs)
        n_deleted = len(table) - len(output)
        done_note = f'{self.name}: done. '
        if n_deleted:
            done_note += f'{n_deleted} rows deleted'
        else:
            done_note += 'No rows deleted'
        logger.info(f'{done_note}, {len(output)} remaining')
        return output
    
    def offer_adjustment(self):
        '''Allow user to adjust check function parameters. Returns boolean
        saying whether user made an adjustment or not.'''
        if not self.kwargs:
            input2('Press enter to acknowledge')
            return False
        answer = yesnohelp(f'Repeat {self.name} with modified args?')
        if answer == 'help':
            logger.info(self.doc)
            return self.offer_adjustment()
        if answer == 'no':
            return False
        assert answer == 'yes', f'error, unknown user answer {answer}'
        for key, val in self.kwargs.items():
            old_kwargs = self.kwargs.copy()
            while True:
                response = input2(f'Enter new {key} value (currently {val}), blank to skip, or \'exit\':')
                if response in blank_responses:
                    break
                if response == 'exit':
                    logger.info('Exiting at user request.')
                    sys.exit(0)
                number = str2float(response)
                if number != None:
                    self.kwargs[key] = float(response)
                    break
            was_adjusted = self.kwargs != old_kwargs
            return was_adjusted
    
    def run_and_adjust(self, table):
        '''Combines run and adjust above.'''
        user_not_done = True
        while user_not_done:
            output = self.run(table)
            was_adjusted = self.offer_adjustment()
            user_not_done = was_adjusted
        return output

# additional user help for cases where we are possibly disabling positioners
fit_err_tol = 0.03
if uargs.set_enabling:
    msg = f'\n\nOption "set-enabling" is on. Details:\n{set_enabling_docstr}\n' + \
          'Please confirm this mode (see paragraph 2 above) is what you want, or exit: '
    yesnohelp(msg, yes=True, no=False, help_=False, exit_=True)

# set up and run checks
fits_to_check = ['STATIC']
if uargs.allow_scale:
    fits_to_check += ['DYNAMIC']
for fit_key in fits_to_check:
    checks = [Check(check_num_outliers, tol=2, key=fit_key)]
    checks += [Check(check_fit_error, tol=fit_err_tol, key=fit_key, set_enabling=uargs.set_enabling)]
checks += [Check(check_flags)]
checks += [Check(check_static_fit_bounds, tighten_factor=0.001)]
checks += [Check(check_xy_offsets, tol=0.5)]
checks += [Check(check_arm_lengths, tol=0.4)]
#checks += [Check(check_recent_rehome)]
checks += [Check(check_uniqueness)]
for check in checks:
    new_table = check.run_and_adjust(new_table)
logger.info('All checks complete')

# finalize which parameters to commit to DB
#  Note 1: I keep the desimeter terminology SCALE_T and SCALE_P here, for
#   consistency. Any conversion to GEAR_CALIB_T, GEAR_CALIB_P shall be performed
#   by the online upload tool (i.e. pecs/set_calibrations.py).
#  Note 2: I include PHYSICAL_RANGE_T and PHYSICAL_RANGE_P in the output table,
#   for completeness / future proofing. However, as of this writing (2020-06-16)
#   there is no specific intent to ever recalibrate them (would require work to
#   demonstrate anticollision safety).
valid_keys = ['LENGTH_R1', 'LENGTH_R2', 'OFFSET_T', 'OFFSET_P', 'OFFSET_X', 'OFFSET_Y',
              'SCALE_T', 'SCALE_P', 'PHYSICAL_RANGE_T', 'PHYSICAL_RANGE_P', disable_key]
commit_keys = {key: commit_prefix + key for key in valid_keys}

# currently unused params (as of 2020-06-16), included for completeness of interface
skip = {'PHYSICAL_RANGE_T', 'PHYSICAL_RANGE_P'}
if not uargs.allow_scale:
    skip |= {'SCALE_T', 'SCALE_P'}

# give user specific decision over whether to commit each field
delayed_log_notes = []  # delaying printout of these confirmation msgs makes interaction clearer
posids_to_commit = set()
for key, commit_key in commit_keys.items():
    if key not in new_table.columns:
        new_table[key] = np.nan  # no data
        skip.add(key)
    if key in skip:
        set_val = False
        method = 'automatically set'
    else:
        while True:
            answer = yesnohelp(f'Shall we commit {key} to online database?')
            if answer == 'help':
                logger.info(f'This will set the field {commit_key} to True or False, for' +
                            ' all remaining positioners in the parameters table (after the' +
                            ' checks which were just completed). It does not send anything' +
                            ' to the database at this time. We are just constructing an' +
                            ' input file right now. Later on, when we feed the input file' +
                            f' to pecs/set_calibrations.py, *then* the {commit_key} field will' +
                            ' tell that script whether or not to actually store the associated' +
                            ' value to the online DB. If you have any doubts about validity of' +
                            ' the data, reply "no" and discuss with the focal plane team.' +
                            ' Devs J.Silber, K.Fanning, or J.Guy should be able to assist.')
            elif answer == 'no':
                set_val = False
                break
            elif answer == 'yes':
                set_val = True
                break
        method = 'set by user'
    new_table[commit_key] = set_val
    delayed_log_notes += [f'{commit_key} {method} to {set_val} for all positioners']
    will_commit = new_table[commit_key]
    posids_to_commit |= set(new_table['POS_ID'][will_commit])
for note in delayed_log_notes:
    logger.info(note)
logger.info(f'Final list of the {len(posids_to_commit)} positioner(s) with any calibration' +
            f' values to be committed:\n{sorted(posids_to_commit)}')

# export
import os
path = os.path.join(out_dir, output_name)
new_table.write(path)
logger.info(f'Saved output posparams to {path}')
logger.info(f'Saved log file to {log_path}')