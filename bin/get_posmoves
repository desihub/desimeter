#!/usr/bin/env python

import os
import psycopg2
import numpy as np
from astropy.table import Table, vstack
import argparse
import time
start_time = time.time()

from desimeter.util import parse_fibers
from desimeter.dbutil import dbquery,get_petal_ids,get_pos_ids,get_petal_loc

enable_keys_moves = {'CTRL_ENABLED'}
enable_keys_calib = {'DEVICE_CLASSIFIED_NONFUNCTIONAL', 'FIBER_INTACT'}

parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter,
                                     description="""Retrieve data from posmove DB and save to disk as CSV table""")

parser.add_argument('--host', type= str, required=False, default='db.replicator.dev-cattle.stable.spin.nersc.org', help="db.replicator.dev-cattle.stable.spin.nersc.org for kpno or beyonce.lbl.gov for petaltest")
parser.add_argument('--port', type= int, required=False, default=60042, help="60042 for kpno or 5432 for petaltest")
parser.add_argument('--password', type= str, required=False, default=None, help="nothing for kpno")
parser.add_argument('--petal-ids', type= str, required=False, default=None, help="comma separated list of petal ids")
parser.add_argument('--exposure-ids', type= str, required=False, default=None, help="comma separated list of exposure ids")
parser.add_argument('--exposure-iters', type= str, required=False, default=None, help="comma separated list of exposure iters")
parser.add_argument('--date-min', type = str, default = "2019-01-01", required = False, help="date min with format YYYY-MM-DD")
parser.add_argument('--date-max', type = str, default = "2030-01-01", required = False, help="date max with format YYYY-MM-DD")
parser.add_argument('--pos-ids', type= str, required=False, default=None, help="comma separated list of positioner ids (same as DEVICE_ID). alternately, argue 'movers' to only pull data files for those robots with move data")
parser.add_argument('-o', '--outdir', type = str, default = "None", required = True, help="output directory where MXXXX.csv files are saved")
parser.add_argument('-c', '--with-calib', action = 'store_true', help="add matching calib from db")
parser.add_argument('-t', '--tp-updates', action='store_true', help="include rows where no move was done but POS_T, POS_P was updated")
parser.add_argument('--recent-rehome-exposure-ids', type= str, required=False, default=None, help="comma separated list of exposure ids where the positioners have been recently rehomed")
parser.add_argument('-comma', '--comma-replacement', type=str, default='||', help='replace commas in data strings with this in output csv files)')
parser.add_argument('-e', '--enabled-history', action='store_true', help=f'filter the data down to just those rows in which a change occurred to one of {enable_keys_moves | enable_keys_calib}')
parser.add_argument('-m', '--merge', action='store_true', help='merge all data into one CSV file (rather than separate files per positioner)')

args  = parser.parse_args()

# example: get_posmoves --host beyonce.lbl.gov --port 5432 --password XXXX --petal-ids 1 --exposure-ids 2107 --exposure-iters 0,1,2,3,4,5,6,7,8,9,10,11 --outdir tmp --nocalib --pos-id M02155

# open connection
comm = psycopg2.connect(host=args.host,port=args.port, database='desi_dev', user='desi_reader',password=args.password)


if args.petal_ids is not None :
    petalids = parse_fibers(args.petal_ids)
else :
    petalids = get_petal_ids(comm)

recent_rehome_exposure_ids=list()
if args.recent_rehome_exposure_ids is not None :
    recent_rehome_exposure_ids=[int(val) for val in args.recent_rehome_exposure_ids.split(",")]

if args.enabled_history:
    enable_keys = enable_keys_moves
    if args.with_calib:
        enable_keys |= enable_keys_calib
    desired_fields = {'moves': 'time_recorded, pos_id, petal_id, device_loc, bus_id, ctrl_enabled, move_cmd, move_val1, move_val2, log_note, exposure_id, exposure_iter, flags',
                      'calib': 'time_recorded, device_classified_nonfunctional, fiber_intact, calib_note'}
else:
    desired_fields = {'moves': '*', 'calib': '*'}

otables = []
for petalid in petalids :

    if args.pos_ids in {None, 'movers'}:
        posids = get_pos_ids(comm, petalid)
    else:
        posids = args.pos_ids.split(",")        

    petal_loc = get_petal_loc(petalid)

    for posid in posids :

        # read data from db
        from_where = f'from posmovedb.positioner_moves_p{int(petalid)} where'
        posid_date = "pos_id='{}' and time_recorded BETWEEN date '{}' and date '{}'".format(posid,args.date_min,args.date_max)
        cmd_exp = ''
        if args.exposure_ids is not None:
            cmd_exp += "exposure_id in ({})".format(args.exposure_ids)
        if args.exposure_iters is not None:
            cmd_exp += ' and ' if cmd_exp else ''
            cmd_exp += "exposure_iter in ({})".format(args.exposure_iters)
        cmd_tp = ''
        if args.tp_updates:
            cmd_idx = f'select pos_move_index {from_where} {posid_date}'
            if cmd_exp:
                cmd_idx += f' and {cmd_exp}'
            result = dbquery(comm, cmd_idx)
            if any(result['pos_move_index']):
                min_idx = min(result['pos_move_index'])
                max_idx = max(result['pos_move_index'])
                max_idx += 1  # capture any tp_updates from just after the exposure or exp iteration
                cmd_tp = f"log_note like '%tp_update%' and pos_move_index >= {min_idx} and pos_move_index <= {max_idx}"
        cmd = f'select {desired_fields["moves"]} {from_where} {posid_date}'
        if cmd_exp and cmd_tp:
            combined = f'({cmd_exp}) or ({cmd_tp})'
            cmd += f' and ({combined})'
        elif cmd_exp:
            cmd += f' and ({cmd_exp})'
        posmoves=dbquery(comm,cmd)

        if args.pos_ids == 'movers':
            has_move_cmd = {x not in {'', None} for x in posmoves['move_cmd']}
            if not any(has_move_cmd):
                continue

        # add petal loc
        posmoves["PETAL_LOC"] = np.repeat(petal_loc,len(posmoves["petal_id"]))

        # make sure there is no comma in log_note
        for i in range(len(posmoves["log_note"])) :
            if posmoves["log_note"][i] is not None:
                posmoves["log_note"][i]=str(posmoves["log_note"][i]).replace(",", args.comma_replacement)

        if args.with_calib :

            # adding calib info
            cmd = f'select {desired_fields["calib"]} from posmovedb.positioner_calibration_p{petalid} where pos_id=\'{posid}\' order by time_recorded'
            calib=dbquery(comm,cmd)

            # get time stamps to match
            tstamp_calib     =  np.array([d.timestamp() for d in calib["time_recorded"]])
            tstamp_posmovedb =  np.array([d.timestamp() for d in posmoves["time_recorded"]])

            rename_keys={'time_recorded':'calib_time_recorded'}

            new_keys=list()
            for k in calib.keys() :
                if k in rename_keys.keys() :
                    new_keys.append(rename_keys[k])
                else :
                    new_keys.append(k)

            for k in new_keys :
                posmoves[k]=list()

            for t in tstamp_posmovedb :
                j=np.where(tstamp_calib<=t)[0][-1]
                for k1,k2 in zip(new_keys,calib.keys()) :
                    posmoves[k1].append(calib[k2][j])

        # save, using astropy.Table io

        # by default convert keys to upper case,
        # but with special cases (of course),
        rename_keys={
            'obs_x':'X_FP',
            'obs_y':'Y_FP',
            'time_recorded':'DATE',
            'calib_time_recorded':'CALIB_DATE',
        }

        otable = Table()
        for k in posmoves.keys() :

            if k in rename_keys.keys() :
                k2=rename_keys[k]
            else :
                k2=k.upper()

            otable[k2]=np.array(posmoves[k])

        otable["RECENT_REHOME"]=np.in1d(otable["EXPOSURE_ID"],recent_rehome_exposure_ids).astype(int)
        
        if args.enabled_history:
            selection = np.array([False]*len(otable))
            selection[0] = True  # by default, include the first row
            otable.sort('DATE')
            for key in enable_keys:
                selection[1:] |= otable[key][1:] != otable[key][:-1]  # detect changes
            otable = otable[selection]

        if not os.path.isdir(args.outdir):
            os.makedirs(args.outdir)
        if args.merge:
            otables.append(otable)
            print(f'retrieved data for {posid}')
        else:
            ofilename="{}/{}.csv".format(args.outdir,posid)
            otable.write(ofilename,overwrite=True)
            print("wrote", ofilename)
if args.merge:
    merged = vstack(otables)
    name = time.strftime('%Y%m%dT%H%M%S%z') + '_posdata.csv'
    path = os.path.join(args.outdir, name)
    merged.write(path)
print(f'Total elapsed time: {time.time() - start_time:.1f} sec')
