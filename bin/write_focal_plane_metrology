#!/usr/bin/env python


import argparse
import sys,os
import numpy as np
import yaml
from desimeter.log import get_logger
from pkg_resources import resource_filename
from astropy.table import Table, vstack
from desimeter.transform.ptl2fp import apply_ptl2fp, fp2ptl

parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter,
                                     description="""Combine petal metrology and petal alignment data into a single CSV file""")

parser.add_argument('-o','--outfile', type = str, default = None, required = True, help = 'output csv file')
parser.add_argument('--no-replacement',action="store_true")

args  = parser.parse_args()
log = get_logger()

log.info("reading petal metrology")
filename = resource_filename('desimeter',"data/UMT-DESI-5421.csv")
log.info(" in {}".format(filename))
spots = Table.read(filename,format="csv")
if 'col0' in spots.dtype.names :
    spots.remove_column('col0')


print("metrology columns:",spots.dtype.names)


# force int type
spots["PETAL_LOC"]=spots["PETAL_LOC"].astype(int)
# keep only petal_loc<10
selection = spots["PETAL_LOC"]<10
spots = spots[:][selection]

pids=np.zeros(spots["PINHOLE_ID"].size,dtype=int)
for i,pid in enumerate(spots["PINHOLE_ID"]) :
    pid=str(pid)
    if pid[0]=="M":
        pids[i]=int(pid[1])
    else :
        try :
            pids[i]=int(pid)
        except ValueError as e :
            pids[i]=0
spots["PINHOLE_ID"]=pids


r=np.sqrt(spots["X_PTL"]**2+spots["Y_PTL"]**2)
ii=np.where( r < 1.)[0]
for i in ii :
    log.warning("BAD DATA {} {} type={} xptl={} yptl={} xmnt={} ymnt={}".format(spots["PETAL_LOC"][i],spots["DEVICE_LOC"][i],spots["DEVICE_TYPE"][i],spots["X_PTL"][i],spots["Y_PTL"][i],spots["X_MNT"][i],spots["Y_MNT"][i]))
spots=spots[:][r>1.] # exclude bad data??

spots = apply_ptl2fp(spots)

spots["LOCATION"] = spots["PETAL_LOC"]*1000+spots["DEVICE_LOC"]

log.info("applying patch")
filename = resource_filename('desimeter',"data/fp-metrology-patch.csv")
log.info(" from {}".format(filename))
patch = Table.read(filename,format="csv")
for i in range(patch["X_FP"].size) :
    selection=(spots["LOCATION"]==patch["LOCATION"][i])&(spots["PINHOLE_ID"]==patch["PINHOLE_ID"][i])
    jj=np.where(selection)[0]
    if jj.size == 0 :
        log.info("Adding LOCATION={} PINHOLE_ID={}".format(patch["LOCATION"][i],patch["PINHOLE_ID"][i]))
        spots.add_row(patch[:][i])
    else :
        if not args.no_replacement :
            j=jj
            log.info("Replacing LOCATION={} PINHOLE_ID={}".format(patch["LOCATION"][i],patch["PINHOLE_ID"][i]))
            spots[:][j] = patch[:][i]

log.info("applying star-based guide GFA metrology patch")
filename = resource_filename('desimeter',"data/fp-metrology-gfa_patch.csv")
log.info(" from {}".format(filename))
gfa_patch = Table.read(filename, format="csv")

for i,row in enumerate(gfa_patch):
    if np.isnan(row['X_PTL']):
        # this is the case of replacing real metrology with tweaked metrology
        spots = spots[np.logical_not((spots['DEVICE_TYPE'] == 'GFA') & (spots['PETAL_LOC'] == row['PETAL_LOC']))]
        x_ptl, y_ptl, _ = fp2ptl(row['PETAL_LOC'], row['X_FP'], row['Y_FP'], z_fp=row['Z_FP'])
        gfa_patch[i]['X_PTL'] = x_ptl
        gfa_patch[i]['Y_PTL'] = y_ptl
        gfa_patch[i]['Z_PTL'] = row['Z_FP']

spots = vstack([spots, gfa_patch])


log.info("add columns with PETAL_ID, DEVICE_ID")
# first version of this file copied from desimodel/data/focalplane/desi-focalplane_2020-03-06T00:00:00.ecsv
filename = resource_filename('desimeter',"data/desi_positioner_indexes.csv")
table_with_ids = Table.read(filename)
location = 1000*np.array(table_with_ids["PETAL_LOC"])+np.array(table_with_ids["DEVICE_LOC"])
loc2index  = {loc:i for i,loc in enumerate(location)}
selection  = (spots["DEVICE_TYPE"]=="POS") | (spots["DEVICE_TYPE"]=="FIF") | (spots["DEVICE_TYPE"]=="GIF")
tableindex = [loc2index[loc] for loc in spots["LOCATION"][selection]]
for k in ["DEVICE_ID","BUS_ID","CAN_ID"] :
    if k == "DEVICE_ID" :
        spots[k] = np.repeat("unknown    ",len(spots))
    else :
        spots[k] = np.repeat(-1,len(spots))
    spots[k][selection] = table_with_ids[k][tableindex]
    print("adding",k,np.array(spots[k][selection][:5]),"...")

ploc2id = {ploc : table_with_ids["PETAL_ID"][table_with_ids["PETAL_LOC"]==ploc][0] for ploc in np.unique(table_with_ids["PETAL_LOC"])}
spots["PETAL_ID"] = [ploc2id[ploc] for ploc in spots["PETAL_LOC"]]

spots.write(args.outfile,format='csv',overwrite=True)

log.info("wrote {}".format(args.outfile))
